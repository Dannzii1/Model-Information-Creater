# -*- coding: utf-8 -*-
"""geekmodel.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1QK8XQxeYiP-OaeFCaxflqLl4ts19j56F
"""

import pandas as pd
import numpy as np

from os import getcwd
df = pd.read_csv('sample_data/mycsv.csv.csv')
print(df.shape)
df.head
# print(getcwd())

df.info()

df.describe()

data1 = df['Position']
data2 = df['Skill 1']
data3 = df['Skill Level 1']
data4 = df['Skill 2']
data5 = df['Skill Level 2']
data6 = df['Skill 3']
data7 = df['Skill Level 3']

data_dict1 = data1.to_dict()
data_dict2 = data2.to_dict()
data_dict3 = data3.to_dict()
data_dict4 = data4.to_dict()
data_dict5 = data5.to_dict()
data_dict6 = data6.to_dict()
data_dict7 = data7.to_dict()

my_Position_dict = {y:x for x,y in data_dict1.items()}
(pd.DataFrame.from_dict(data=my_Position_dict, orient='index').to_csv('my_Position_dict.csv', header=False))
my_Position_dict

my_Skill_1_dict = {y:x for x,y in data_dict2.items()}
(pd.DataFrame.from_dict(data=my_Skill_1_dict, orient='index').to_csv('my_Skill_1_dict.csv', header=False))

my_Skill_Level_1_dict = {y:x for x,y in data_dict3.items()}
(pd.DataFrame.from_dict(data=my_Skill_Level_1_dict, orient='index').to_csv('my_Skill_Level_1_dict.csv', header=False))

my_Skill_2_dict = {y:x for x,y in data_dict4.items()}
(pd.DataFrame.from_dict(data=my_Skill_2_dict, orient='index').to_csv('my_Skill_2_dict.csv', header=False))

my_Skill_Level_2_dict = {y:x for x,y in data_dict5.items()}
(pd.DataFrame.from_dict(data=my_Skill_Level_2_dict, orient='index').to_csv('my_Skill_Level_2_dict.csv', header=False))

my_Skill_3_dict = {y:x for x,y in data_dict6.items()}
(pd.DataFrame.from_dict(data=my_Skill_3_dict, orient='index').to_csv('my_Skill_3_dict.csv', header=False))

my_Skill_Level_3_dict = {y:x for x,y in data_dict7.items()}
(pd.DataFrame.from_dict(data=my_Skill_Level_3_dict, orient='index').to_csv('my_Skill_Level_3_dict.csv', header=False))

my_Skill_1_dict

my_Skill_Level_1_dict

my_Skill_2_dict

my_Skill_Level_2_dict

my_Skill_3_dict

my_Skill_Level_3_dict

modeldf=df[['Position','GPA','Skill 1','Skill Level 1','Skill 2','Skill Level 2','Skill 3','Skill Level 3']]

modeldf['Position']= modeldf['Position'].map(my_Position_dict)
modeldf['Skill 1']= modeldf['Skill 1'].map(my_Skill_1_dict)
modeldf['Skill Level 1']= modeldf['Skill Level 1'].map(my_Skill_Level_1_dict)
modeldf['Skill 2']= modeldf['Skill 2'].map(my_Skill_2_dict)
modeldf['Skill Level 2']= modeldf['Skill Level 2'].map(my_Skill_Level_2_dict)
modeldf['Skill 3']= modeldf['Skill 3'].map(my_Skill_3_dict)
modeldf['Skill Level 3']= modeldf['Skill Level 3'].map(my_Skill_Level_3_dict)


modeldf.head()

X=modeldf[['GPA','Skill 1','Skill Level 1','Skill 2','Skill Level 2','Skill 3','Skill Level 3']].value
Y=modeldf[['Position']].value

from sklearn.model_selection import train_test_split

def extractData(df,target):
    Y = df[target]
    X = df.drop([target], axis=1)
    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=42)
    return X_train, X_test, y_train, y_test

train,test_input,target,test_output = extractData(modeldf,'Position')

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Activation, Flatten

def create_Neural_Net():
    NN_model = Sequential()
    
    NN_model.add(Dense(128, kernel_initializer='normal',input_dim = train.shape[1], activation='relu'))
    
    NN_model.add(Dense(256, kernel_initializer='normal',activation='relu'))
    NN_model.add(Dense(256, kernel_initializer='normal',activation='relu'))
    NN_model.add(Dense(256, kernel_initializer='normal',activation='relu'))
    
    NN_model.add(Dense(1, kernel_initializer='normal',activation='linear'))
    
    NN_model.compile(loss='mean_absolute_error', optimizer='adam', metrics=['mean_absolute_error'])
    return NN_model

model = create_Neural_Net()
type(model)

# Checkpoint the weights for best model on validation accuracy

from tensorflow.keras.callbacks import ModelCheckpoint

# checkpoint
checkpoint_name="weights.best.hdf5"
checkpoint = ModelCheckpoint(checkpoint_name, monitor='val_loss', verbose=1, save_best_only=True, mode='auto')
callbacks_list = [checkpoint]

model.fit(train, target, validation_split=0.20, epochs=200, batch_size=600, callbacks=callbacks_list, verbose=0)

model.load_weights("weights.best.hdf5")
# Compile model (required to make predictions)
model.compile(loss='mean_absolute_error', optimizer='adam', metrics=['mean_absolute_error'])
print("Created model and loaded weights from file")


# estimate accuracy on whole dataset using loaded weights
scores = model.evaluate(train, target, verbose=0)
print("%s: %.2f" % (model.metrics_names[0], scores[0]))

predictions = model.predict(test_input)

print("predictions: \n",predictions)
print("\n\nactial values: \n",test_output)